{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data.dataset import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/train_dataset.pickle', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "print (\"finish loading dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devide_dataset(dataset, start_ratio, end_ratio):\n",
    "    train_dataset = dataset[:int(len(dataset)*start_ratio)] + dataset[int(len(dataset)*end_ratio):]\n",
    "    valid_dataset = dataset[int(len(dataset)*start_ratio):int(len(dataset)*end_ratio)]\n",
    "    return train_dataset, valid_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = 0\n",
    "\n",
    "EMBEDDING_SIZE = 10+25+1\n",
    "ENCODING_SIZE = 32\n",
    "SEQ_LENGTH = 15\n",
    "\n",
    "batch_size = 512\n",
    "num_epochs = 20\n",
    "learning_rate = 1e-2\n",
    "clipping = 0.15\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model,train_loader,valid_loader,criterion,learning_rate,num_epochs,model_name):\n",
    "    best_mrr = -9999\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, [10,15], gamma=0.2)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            session = data[0].type(torch.FloatTensor).cuda(gpu_device)\n",
    "            display = data[1].type(torch.FloatTensor).cuda(gpu_device)\n",
    "            encoding = data[2].type(torch.FloatTensor).cuda(gpu_device)\n",
    "            criteria = data[3].type(torch.FloatTensor).cuda(gpu_device)\n",
    "            device = data[4].type(torch.FloatTensor).cuda(gpu_device)\n",
    "            real_clicked_item = data[5].type(torch.LongTensor).cuda(gpu_device)\n",
    "            \n",
    "            output = model(session, display, encoding, criteria, device)\n",
    "            loss1 = criterion(output[0], real_clicked_item)\n",
    "            loss2 = criterion(output[1], real_clicked_item)\n",
    "            loss = 0.10*loss1 + 1.00*loss2\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), clipping)\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "        real_all, pred_all = eval(model, valid_loader, model_name)\n",
    "        now_mrr = calculate_mrr(pred_all, real_all)\n",
    "        if best_mrr < now_mrr:\n",
    "            best_mrr = now_mrr\n",
    "            print ('epoch {} - mrr: {}'.format(epoch, best_mrr))\n",
    "            file_name = 'best_valid_'+model_name+'.pth'\n",
    "            torch.save(model.state_dict(), file_name)\n",
    "        \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mrr(pred, real):\n",
    "    reciprocal_rank = []\n",
    "    for idx in range(len(pred)):\n",
    "        reciprocal_rank.append(1/(np.where(np.argsort(pred[idx])[::-1]==(real[idx]))[0][0]+1))\n",
    "    mrr = np.mean(reciprocal_rank)\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,test_loader,model_name):\n",
    "    model.eval()\n",
    "    real_all = []\n",
    "    pred_all = []\n",
    "\n",
    "    for i, data in enumerate(test_loader):\n",
    "        session = data[0].type(torch.FloatTensor).cuda(gpu_device)\n",
    "        display = data[1].type(torch.FloatTensor).cuda(gpu_device)\n",
    "        encoding = data[2].type(torch.FloatTensor).cuda(gpu_device)\n",
    "        criteria = data[3].type(torch.FloatTensor).cuda(gpu_device)\n",
    "        device = data[4].type(torch.FloatTensor).cuda(gpu_device)\n",
    "        real_clicked_item = data[5].type(torch.LongTensor).cuda(gpu_device)\n",
    "        real_all += real_clicked_item.cpu().detach().numpy().tolist()\n",
    "        \n",
    "        output = model(session, display, encoding, criteria, device)\n",
    "        pred_all += output[1].cpu().detach().numpy().tolist()\n",
    "        \n",
    "    real_all = np.array(real_all)\n",
    "    pred_all = np.array(pred_all)\n",
    "\n",
    "    return real_all, pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_lst = list(range(39))\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=EMBEDDING_SIZE, hidden_size=32, num_layers=2, bidirectional=True, batch_first=True)\n",
    "        self.lstm_fc = nn.Sequential(\n",
    "            nn.Linear(64+12+3, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 25))\n",
    "        \n",
    "        self.conv1x1 = nn.Sequential(\n",
    "            nn.Conv1d(1+ENCODING_SIZE+len(idx_lst), 64, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.conv =  nn.Sequential(\n",
    "            nn.Conv1d(64, 128, kernel_size=3, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=3, bias=False),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 256, kernel_size=3, bias=False),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.conv_fc = nn.Sequential(\n",
    "            nn.Linear(256*15, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(p=0.8))\n",
    "        \n",
    "        self.final_fc = nn.Linear(512, 25)\n",
    "\n",
    "    def forward(self, session, display, encoding, criteria, device):\n",
    "        output, (hidden, cell) = self.lstm(session, None)\n",
    "        output = output[:,SEQ_LENGTH-1,:]\n",
    "        output = torch.cat([output, criteria, device], dim=1)\n",
    "        session_output = self.lstm_fc(output)\n",
    "\n",
    "        display = display[:,idx_lst,:]\n",
    "        display = torch.cat([session_output.view(-1, 1, 25), encoding, display], dim=1)\n",
    "        display_output = self.conv1x1(display)\n",
    "        conv_output = self.conv(display_output).view(-1, 256*15)\n",
    "        final_feature = self.conv_fc(conv_output)\n",
    "        final_output = self.final_fc(final_feature)\n",
    "        return session_output, final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    start_ratio = i*0.2\n",
    "    end_ratio = start_ratio+0.2\n",
    "    train_dataset, valid_dataset = devide_dataset(dataset, start_ratio, end_ratio)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=6, pin_memory=True, shuffle=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=batch_size, num_workers=6, pin_memory=True, shuffle=False)\n",
    "\n",
    "    net = Net().cuda(gpu_device)\n",
    "    print (start_ratio)\n",
    "    fit(net, train_loader, valid_loader, criterion, learning_rate, num_epochs, 'net{}'.format(i+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/line_final.pickle', 'rb') as f:\n",
    "    submissions = pickle.load(f)\n",
    "with open('data/test_dataset.pickle', 'rb') as f:\n",
    "    test_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(submissions)):\n",
    "    if len(submissions[i][4]) != 25:\n",
    "        submissions[i][4] = submissions[i][4] + ['-9999']*(25-len(submissions[i][4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(idx):\n",
    "    net = Net().cuda(gpu_device)\n",
    "    file_name = 'best_valid_net{}.pth'.format(idx)\n",
    "    net.load_state_dict(torch.load(file_name))\n",
    "    net.eval()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pred = np.zeros([len(test_dataset), 25])\n",
    "for idx in range(1, 6):\n",
    "    net = load_net(idx)\n",
    "    pred_all = []\n",
    "    for i, data in enumerate(test_loader):\n",
    "        session = data[0].type(torch.FloatTensor).cuda(gpu_device)\n",
    "        display = data[1].type(torch.FloatTensor).cuda(gpu_device)\n",
    "        encoding = data[2].type(torch.FloatTensor).cuda(gpu_device)\n",
    "        criteria = data[3].type(torch.FloatTensor).cuda(gpu_device)\n",
    "        device = data[4].type(torch.FloatTensor).cuda(gpu_device)\n",
    "\n",
    "        output = net(session, display, encoding, criteria, device)\n",
    "        pred_all += list(F.softmax(output[1], dim=1).cpu().detach().numpy())\n",
    "    ensemble_pred += np.array(pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index = np.argsort(-ensemble_pred)\n",
    "\n",
    "for i in range(len(sorted_index)):\n",
    "    tmp_submission = submissions[i][4]\n",
    "    sorted_submission = [tmp_submission[idx] for idx in sorted_index[i] if tmp_submission[idx]!='-9999']\n",
    "    sorted_submission = ' '.join(sorted_submission)\n",
    "    submissions[i].append(sorted_submission)\n",
    "\n",
    "submission_df = pd.DataFrame(submissions, columns=['user_id', 'session_id', 'timestamp', 'step', 'impressions', 'item_recommendations'])\n",
    "submission_df = submission_df[['user_id', 'session_id', 'timestamp', 'step', 'item_recommendations']]\n",
    "submission_df.to_csv('final_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
